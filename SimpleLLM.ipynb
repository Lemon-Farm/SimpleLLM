{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d1ce3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c0f71f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    text_path = 'dataset/sherlock-holm.es_stories_plain-text_advs.txt'\n",
    "    max_length = 64\n",
    "    stride = 4\n",
    "    batch_size = 96\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c7a351fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed text length: 558453, words: 104321\n",
      "142064\n"
     ]
    }
   ],
   "source": [
    "# 전처리 및 토크나이즈\n",
    "with open(cfg.text_path, 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# 줄 앞뒤 공백 제거 및 연속된 빈 줄 1개로 정리\n",
    "raw_text = re.sub(r'\\s+\\n', '\\n', raw_text)\n",
    "raw_text = re.sub(r'^\\s+', '', raw_text, flags=re.MULTILINE)\n",
    "raw_text = re.sub(r'\\n{2,}', '\\n\\n', raw_text)\n",
    "\n",
    "# 제목 삭제\n",
    "raw_text = re.sub(r'THE ADVEN.*\\n', '', raw_text, flags=re.MULTILINE)\n",
    "\n",
    "# 목차나 저자 등 메타데이터 제거\n",
    "raw_text = re.sub(r'Arthur Conan Doyle', '', raw_text, flags=re.IGNORECASE)\n",
    "raw_text = re.sub(r'\\bTable of contents\\b.*?(?=CHAPTER I)', '', raw_text, flags=re.DOTALL|re.IGNORECASE)\n",
    "raw_text = re.sub(r'chapter ([0~9]|[ivx])', '', raw_text, flags=re.IGNORECASE)\n",
    "raw_text = re.sub(r'----.*', '', raw_text, flags=re.DOTALL)\n",
    "\n",
    "\n",
    "# 특수문자, 과도한 빈칸 정리\n",
    "raw_text = re.sub(r'[“”]', '\"', raw_text)\n",
    "raw_text = re.sub(r\"[‘’]\", \"'\", raw_text)\n",
    "raw_text = re.sub(r' +', ' ', raw_text)\n",
    "\n",
    "# 앞뒤 전체 공백 제거\n",
    "raw_text = raw_text.strip()\n",
    "\n",
    "# 전처리된 텍스트 결과\n",
    "preprocessed_text = raw_text\n",
    "print(f\"preprocessed text length: {len(preprocessed_text)}, words: {len(preprocessed_text.split())}\")\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# 토크나이즈\n",
    "tokenized_text = tokenizer.encode(preprocessed_text)\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "26c6b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset) :\n",
    "    def __init__(self, tokenized_text, cfg) :\n",
    "        self.tokenized_text = tokenized_text\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.input_ids = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(0, len(self.tokenized_text) - self.cfg.max_length, self.cfg.stride) :\n",
    "            self.input_ids.append(self.tokenized_text[i:i+self.cfg.max_length])\n",
    "            self.labels.append(self.tokenized_text[i+1:i+self.cfg.max_length+1])\n",
    "        \n",
    "        self.input_ids = torch.tensor(self.input_ids)\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def print(self) :\n",
    "        return self.input_ids[1], self.labels[1]\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        return self.input_ids[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82eb8569-c24c-475e-96ba-b4311dfadac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  318,  1464,   262,  2415,    13,   314,   423, 25129,  2982,   683,\n",
       "           198,   434,   295,   607,   739,   597,   584,  1438,    13,   554,\n",
       "           465,  2951,   673, 39097,   274,   290,   198, 28764,  6351,   689,\n",
       "           262,  2187,   286,   607,  1714,    13,   632,   373,   407,   326,\n",
       "           339,  2936,   597,   198,   368,  9650, 22107,   284,  1842,   329,\n",
       "          7181,   710,  1215,  1754,    13,  1439, 10825,    11,   290,   326,\n",
       "           530,   198, 31722,    11]),\n",
       " tensor([ 1464,   262,  2415,    13,   314,   423, 25129,  2982,   683,   198,\n",
       "           434,   295,   607,   739,   597,   584,  1438,    13,   554,   465,\n",
       "          2951,   673, 39097,   274,   290,   198, 28764,  6351,   689,   262,\n",
       "          2187,   286,   607,  1714,    13,   632,   373,   407,   326,   339,\n",
       "          2936,   597,   198,   368,  9650, 22107,   284,  1842,   329,  7181,\n",
       "           710,  1215,  1754,    13,  1439, 10825,    11,   290,   326,   530,\n",
       "           198, 31722,    11,   547]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = MyDataset(tokenized_text, cfg)\n",
    "test.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2498f24",
   "metadata": {},
   "source": [
    "모델 참조 : https://www.manning.com/books/build-a-large-language-model-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3b6ee931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.n_vocab\n",
    "print(VOCAB_SIZE)\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "L = 128  # Shortened context length (orig: 1024)\n",
    "E = 768  # Embedding dimension\n",
    "H = 12  # Number of attention heads\n",
    "NUM_LAYERS = 6  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "078847d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module) :\n",
    "    def __init__(self, din, dout) :\n",
    "        super().__init__()\n",
    "        \n",
    "        assert dout % H == 0, \"dout must be devided by NUM_HEADS\"\n",
    "        \n",
    "        self.din = din\n",
    "        self.dout = dout\n",
    "        self.D = dout // H\n",
    "        \n",
    "        self.W_Q = nn.Linear(din, dout)\n",
    "        self.W_K = nn.Linear(din, dout)\n",
    "        self.W_V = nn.Linear(din, dout)\n",
    "        self.out_proj = nn.Linear(dout, dout)\n",
    "        self.dropout = nn.Dropout(p=DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(L, L), diagonal=1)) # Causal Attn을 위한 Mask\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        B, L, E = x.shape\n",
    "        D = self.D\n",
    "        \n",
    "        # Query, Key, Value Matrix 생성 (B, L, E)\n",
    "        Q = self.W_Q(x)\n",
    "        K = self.W_K(x)\n",
    "        V = self.W_V(x)\n",
    "        \n",
    "        # Multihead 반영 (B, L, E) -> (B, L, H, D) -> (B, H, L, D)\n",
    "        Q = Q.view(B, L, H, D).transpose(1, 2)\n",
    "        K = K.view(B, L, H, D).transpose(1, 2)\n",
    "        V = V.view(B, L, H ,D).transpose(1, 2)\n",
    "        \n",
    "        # Attention Score 구하기\n",
    "        attn_scores = Q @ K.transpose(2, 3) # (B, H, L, L)\n",
    "        mask = self.mask[:L, :L].bool()\n",
    "        attn_scores = attn_scores.masked_fill(mask, -1e9)\n",
    "        attn_scores = attn_scores / (D ** 0.5)\n",
    "        \n",
    "        # Attention Weight 구하기\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Context Vector 구하기\n",
    "        CV = attn_weights @ V # (B, H, L, D)\n",
    "        CV = CV.transpose(1, 2).contiguous().view(B, L, E)\n",
    "        CV = self.out_proj(CV)\n",
    "        \n",
    "        return CV\n",
    "    \n",
    "class LayerNorm(nn.Module) :\n",
    "    def __init__(self, dim, eps=1e-5) :\n",
    "        super().__init__()\n",
    "        \n",
    "        # 파라미터 생성\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(dim))\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps) * self.gamma + self.beta\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(E, 4*E),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*E, E),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "class TransformerBlock(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = MultiheadAttention(E, E)\n",
    "        self.norm1 = LayerNorm(E)\n",
    "        self.norm2 = LayerNorm(E)\n",
    "        self.ff = FeedForward()\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "        \n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class SimpleLLM(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(VOCAB_SIZE, E)\n",
    "        self.positional_embedding = nn.Embedding(L, E)\n",
    "        self.dropout_embedding = nn.Dropout(DROP_RATE)\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)]\n",
    "        )\n",
    "        \n",
    "        self.last_norm = LayerNorm(E)\n",
    "        self.out = nn.Linear(E, VOCAB_SIZE, bias=False)\n",
    "        \n",
    "    def forward(self, input_ids) :\n",
    "        B, L = input_ids.shape\n",
    "        tok_emb = self.token_embedding(input_ids)\n",
    "        pos_emb = self.positional_embedding(torch.arange(L, device=input_ids.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.dropout_embedding(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.last_norm(x)\n",
    "        logits = self.out(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cea0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 1]: 100%|██████████| 370/370 [01:42<00:00,  3.62it/s, loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 4.434826627293148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 2]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 1.6000405967235565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 3]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.3873643256522514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 4]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.22701506514001538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 5]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.1819407149343877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 6]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.15960212176716004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 7]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.1472369960433728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 8]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.13801623172051197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 9]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.13253490220050554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 10]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.1269838837554326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 11]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.12325755836995872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 12]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.12019976431856284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 13]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.11790154028583218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 14]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.126] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.11494085307459573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 15]: 100%|██████████| 370/370 [01:43<00:00,  3.56it/s, loss=0.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.11305300539007059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 16]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.114] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.11149368743236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 17]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.115] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.10955652489855483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 18]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.10773113818990218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 19]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.111] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.10638316036076159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 20]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.119] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.10509153483687221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 21]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.10352847223749032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 22]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.10290500851901802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 23]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.114] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.1020241076680454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 24]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.10104626846071836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 25]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.0999959820025676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 26]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.098749515957929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 27]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09839380983565305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 28]: 100%|██████████| 370/370 [01:43<00:00,  3.59it/s, loss=0.0987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09787648714877464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 29]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09730466032350385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 30]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.099] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09603759368529191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 31]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.0944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09563091310697633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 32]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.091] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09547921425184688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 33]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09432954109601073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 34]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09415597841143608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 35]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.0984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09419406219511418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 36]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.0985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09306228821342055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 37]: 100%|██████████| 370/370 [01:43<00:00,  3.58it/s, loss=0.098] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.0926113131682615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 38]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.0938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09221814919162441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 39]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.0978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09228985337792216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 40]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09156868572573404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 41]: 100%|██████████| 370/370 [01:43<00:00,  3.57it/s, loss=0.0945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss : 0.09134422476227219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch : 42]:  38%|███▊      | 141/370 [00:39<01:03,  3.59it/s, loss=0.0933]"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = SimpleLLM().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.01)\n",
    "train_dataset = MyDataset(tokenized_text, cfg)\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, num_workers=8, pin_memory=True, shuffle=True)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"[Epoch : {epoch + 1}]\")\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_ids, labels in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device) # (B, L)\n",
    "        \n",
    "        logits = model(input_ids) # (B, L, V)\n",
    "        loss = F.cross_entropy(logits.flatten(0, 1), labels.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_loss = epoch_loss / len(pbar)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    print(f\"Avg Loss : {avg_loss}\")\n",
    "    torch.save(model.state_dict(), f\"model/simplellm_epoch{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cb8bf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 결과 출력\n",
    "plt.plot(epoch_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d2255628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name  please time I'll forehead five minutes.' Heaven bless\n"
     ]
    }
   ],
   "source": [
    "# 문장 생성\n",
    "\n",
    "# 모델 불러오기\n",
    "model.load_state_dict(torch.load('./model/simplellm_epoch30.pth', map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "text = \"My name \" # 시작 문장\n",
    "\n",
    "input_ids = tokenizer.encode(text)\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0) # (1, L)\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "repetition_penalty = 2.0  # ★ 추가 (1.1~1.5 보통)\n",
    "\n",
    "generation_len = 10\n",
    "for _ in range(generation_len):\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids)  # (1, L, V)\n",
    "\n",
    "    logits = logits[:, -1, :]     # (1, V)\n",
    "    logits = logits / 0.5         # temperature\n",
    "\n",
    "    # ★ repetition penalty 적용\n",
    "    for token_id in set(input_ids[0].tolist()):\n",
    "        logits[0, token_id] /= repetition_penalty\n",
    "\n",
    "    next_token = torch.argmax(logits, dim=-1, keepdim=True)  # (1, 1)\n",
    "    input_ids = torch.cat((input_ids, next_token), dim=-1)\n",
    "\n",
    "    \n",
    "input_ids = input_ids.squeeze(0) # (Generation_Len, )\n",
    "generated_text = tokenizer.decode(input_ids.tolist())\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57151c37-4646-4288-ab17-55d9ab4f11ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.35\t 2370\t  evidence\n",
      "11.92\t 373\t  was\n",
      "10.76\t 2166\t  front\n",
      "10.75\t 6178\t  adm\n",
      "10.59\t 4692\t  cold\n",
      "10.46\t 2696\t ises\n",
      "10.43\t 7932\t  wonderful\n",
      "10.40\t 7954\t  angry\n",
      "10.23\t 26347\t  speeding\n",
      "10.06\t 12000\t  seized\n",
      " evidence\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"The evidence was\") # 토큰 id의 list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# 가장 확률이 높은 단어 10개 출력\n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# 가장 확률이 높은 단어 출력\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50097ed-a6fa-43c0-a300-750b95609129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
